# SearXNG ã¨ Ollama ã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢ãƒãƒ£ãƒƒãƒˆ

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```elixir
Mix.install([
  {:req, "~> 0.5"},
  {:ollama, "~> 0.8"},
  {:chunx, github: "preciz/chunx"},
  {:hnswlib, "~> 0.1"},
  {:kino, "~> 0.15"}
])
```

## æ¤œç´¢æ©Ÿèƒ½ã®å®Ÿè£…

SearXNG ã® API ã‚’ä½¿ç”¨ã—ã¦æ¤œç´¢ã‚’å®Ÿè¡Œã™ã‚‹é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ï¼š

```elixir
search = fn query ->
  "http://searxng:8080/search"
  |> Req.get!(params: [q: query, format: "json"])
  |> Map.get(:body)
end
```

## æ¤œç´¢ã®ãƒ†ã‚¹ãƒˆ

ã€Œã‚„ã›ã†ã¾ã€ã‚’æ¤œç´¢ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼š

```elixir
results =
  "ã‚„ã›ã†ã¾"
  |> search.()
  |> Map.get("results")
```

## ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å–å¾—

æ¤œç´¢çµæœã‹ã‚‰ä¸Šä½ã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ã—ã¾ã™ï¼š

```elixir
documents =
  results
  |> Enum.filter(fn result ->
    String.starts_with?(result["url"], "https")
  end)
  |> Enum.slice(0..9)
  |> Enum.map(fn result ->
    content =
      result["url"]
      |> URI.encode()
      |> Req.get!()
      |> Map.get(:body)
      |> String.replace(~r/\n/, "ğŸ¦›")
      |> String.replace(~r/<script.*?\/script>/, "")
      |> String.replace(~r/<style.*?\/style>/, "")
      |> String.replace(~r/[\s]+/, "")
      |> String.replace("&nbsp;", " ")
      |> String.replace(~r/<br.*?>/, "\n")
      |> String.replace(~r/<.*?>/, "\t")
      |> String.replace("ğŸ¦›", "\n")
      |> String.replace(~r/[\r\n\t]+/, "\n")
      |> String.trim()

    %{
      url: result["url"],
      title: result["title"],
      content: content
    }
  end)
  |> Enum.filter(fn result ->
    String.valid?(result.content)
  end)
  |> Enum.slice(0..4)
```

## ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°å‡¦ç†

Chunx ã§ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¾ã™ï¼š

```elixir
{:ok, tokenizer} = Tokenizers.Tokenizer.from_file("/data/models/ruri_base/tokenizer.json")
client = Ollama.init(base_url: "http://ollama:11434/api", receive_timeout: 300_000)
Ollama.pull_model(client, name: "kun432/cl-nagoya-ruri-base")

embedding_fn = fn texts ->
  texts
  |> Enum.map(fn text ->
    client
    |> Ollama.embed(
      model: "kun432/cl-nagoya-ruri-base",
      input: "æ–‡ç« : #{text}"
    )
    |> elem(1)
    |> Map.get("embeddings")
    |> hd()
    |> Nx.tensor()
  end)
end

chunks =
  documents
  |> Enum.map(fn document ->
    {:ok, doc_chunks} =
      document.content
      |> Chunx.Chunker.Semantic.chunk(
        tokenizer,
        embedding_fn,
        delimiters: ["ã€‚", ".", "!", "?", "\n"]
      )

    doc_chunks
    |> Enum.map(fn chunk ->
      chunk.sentences
      |> Enum.filter(fn sentence -> String.length(sentence.text) > 2 end)
      |> Enum.map(fn sentence ->
        document
        |> Map.put(:chunk, chunk.text)
        |> Map.put(:sentence, sentence.text)
        |> Map.put(:embedding, sentence.embedding)
        |> Map.delete(:content)
      end)
    end)
    |> Enum.concat()
  end)
  |> Enum.concat()
```

## ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ

ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã—ãŸãƒ†ã‚­ã‚¹ãƒˆæ¯ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ç™»éŒ²ã—ã¾ã™ï¼š

```elixir
{:ok, index} = HNSWLib.Index.new(:cosine, 768, 1_000_000)

chunks
|> Enum.each(fn chunk ->
  HNSWLib.Index.add_items(index, chunk.embedding)
end)
```

## è³ªå•å¿œç­”

ã€Œã‚„ã›ã†ã¾ã®ææ–™ã¯ä½•ã§ã™ã‹ã€ã¨ã„ã†ãƒ†ã‚­ã‚¹ãƒˆã«è¿‘ã„æ–‡ç« ã‚’æ¤œç´¢ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼š

```elixir
query = "ã‚„ã›ã†ã¾ã®ææ–™ã¯ä½•ã§ã™ã‹"

embeddings =
  client
  |> Ollama.embed(
    model: "kun432/cl-nagoya-ruri-base",
    input: "ã‚¯ã‚¨ãƒª: #{query}"
  )
  |> elem(1)
  |> Map.get("embeddings")
  |> hd()
  |> Nx.tensor()

{:ok, labels, dist} = HNSWLib.Index.knn_query(index, embeddings, k: 10)

context =
  labels
  |> Nx.to_flat_list()
  |> Enum.map(fn index ->
    chunks
    |> Enum.at(index)
    |> Map.get(:chunk)
  end)
  |> Enum.join("\n\n")

Kino.Markdown.new(context)
```

## AI ãƒãƒ£ãƒƒãƒˆ

ãƒãƒ£ãƒƒãƒˆã«ã¯ Gemma 2 ã‚’ä½¿ç”¨ã—ã¾ã™ï¼š

```elixir
Ollama.pull_model(client, name: "hf.co/alfredplpl/gemma-2-2b-jpn-it-gguf")
Ollama.preload(client, model: "hf.co/alfredplpl/gemma-2-2b-jpn-it-gguf")

{:ok, %{"response" => response}} =
  Ollama.completion(
    client,
    model: "hf.co/alfredplpl/gemma-2-2b-jpn-it-gguf",
    prompt: """
    è³ªå•ã«ä¸€èˆ¬çš„ãªæƒ…å ±ã§ã¯ãªãã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã®ã¿ã«åŸºã¥ã„ã¦å›ç­”ã—ã¦ãã ã•ã„

    ## ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±

    #{context}

    ## è³ªå•

    #{query}
    """
  )

Kino.Markdown.new(response)
```
