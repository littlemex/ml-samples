{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75d4002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers langchain faiss-gpu sentence_transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3805b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00862264633178711,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c714d3d9f6f432189b0a198dc726048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "model_name = \"cerebras/Cerebras-GPT-13B\"\n",
    "cache_dir = \"/home/ec2-user/SageMaker/tmp\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac309f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", model=model, tokenizer=tokenizer,\n",
    "    max_new_tokens=100, early_stopping=True, no_repeat_ngram_size=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2810c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89400f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "  {\n",
    "    \"question\": \"Context: Hayao Miyazaki (born January 5, 1941) is a Japanese film director, animator and manga artist. Also known as Saburo Akitsu and Teruki. In credit titles such as movies, it is sometimes written as Hayao Miyazaki.\\n\\nDirector of Studio Ghibli Co., Ltd. Director of Tokuma Memorial Animation Culture Foundation Director, Mitaka City Animation Museum (Mitaka no Mori Ghibli Museum).\\n\\nFrom Tokyo City, Tokyo Graduated from Gakushuin University with a degree in politics and economics.Koganei City, Tokyo Honorary Citizen of Mitaka City.Lives in Tokorozawa City, Saitama Prefecture. Joined the animation production company Studio Ghibli as a film director and became a director in April 2005. He is also the owner of the Mitaka City Animation Museum (Mitaka no Mori Ghibli Museum), which he planned and developed.\\n\\ nIn his personal office, there was Futabariki Co., Ltd. He mainly managed Miyazaki's copyrights, and he used to serve as the president, but in 2016 he merged with Studio Ghibli. and disbanded.\\n\\nHe is also known as a smoker.\\nQuestion: What is the name of the museum where Hayao Miyazaki is the owner?\",\n",
    "    \"answer\": \"Mitaka City Animation Museum\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Context: Godzilla is a monster movie that has been produced for more than half a century since the first movie was released in 1954. Since then, this technique has become the mainstream of Japanese tokusatsu films and TV tokusatsu programs.In addition to the fights between monsters and monsters, the portrayals of the people around them, such as the fleeing residents and the army fighting and defending, have been well received in each episode. It has been screened not only in Japan but also overseas, gaining popularity, and is the only Japanese character registered on the Hollywood Walk of Fame.\\nQuestion: Godzilla was filmed by an actor. where is this done?\",\n",
    "    \"answer\": \"plush toy\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Context: Neapolitan is a Western dish of boiled spaghetti stir-fried with onions, green peppers, ham, etc., in tomato ketchup. A Japanese-style pasta dish created in Japan, similar to Italian cuisine with a similar name. Spaghetti alla napoletana is different from spaghetti alla napoletana.There are a wide variety of pasta dishes with names similar to Napolitan, but in this article, we use soft wheat, which was widely served in Japanese cafes and Western restaurants after World War II. I will mainly explain the thin noodles fried with ketchup.I will also explain similar pasta dishes around it.\\nQuestion: What sauce is used for Neapolitan?\",\n",
    "    \"answer\": \"Tomato ketchup\"\n",
    "  },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4b5abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.example_generator import generate_example\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# プロンプトテンプレートの準備\n",
    "example_template = PromptTemplate(\n",
    "    template=\"{question}\\n{answer}\", \n",
    "    input_variables=[\"question\", \"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b748ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The name is similar, so I think it's a good example of how to find a name that is related to a word. If you look at the word \"napolette\" in the dictionary, you can see that it means \"thin noodles\".\n",
      "napa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# データの生成\n",
    "new_example = generate_example(examples, llm, example_template)\n",
    "print(new_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26985535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
